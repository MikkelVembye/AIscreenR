% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ftscreen.r
\name{ftscreen}
\alias{ftscreen}
\title{Full-text screening with OpenAI API models}
\usage{
ftscreen(
  file_path,
  prompt = NULL,
  protocol_file_path = NULL,
  api_key = get_api_key(),
  vector_stores_name,
  model = "gpt-4o-mini",
  top_p = 1,
  temperature = 0.7,
  decision_description = FALSE,
  assistant_name = "file assistant screening",
  assistant_description =
    "An assistant to review a file and decide if it should be included or excluded in further studies based on a protocol or prompt.",
  assistant_instructions =
    "You are an assistant that helps in reviewing files to determine their relevance based on specific protocols or prompts. IMPORTANT: You must ALWAYS follow this exact sequence: 1. FIRST, check if the text contains any references to supplementary materials, appendices, or additional information using the supplementary_check function. 2. THEN, determine whether the study should be included or excluded based on the protocol or prompt provided. Be explicit about whether the study should be included or excluded in further studies based on the evaluation criteria. If the study meets the protocol criteria, then it should be included in further studies.",
  messages = TRUE,
  reps = 1,
  max_tries = 16,
  time_info = TRUE,
  token_info = TRUE,
  max_seconds = NULL,
  is_transient = gpt_is_transient,
  backoff = NULL,
  after = NULL,
  rpm = 10000,
  seed_par = NULL,
  progress = TRUE,
  incl_cutoff_upper = 0.5,
  incl_cutoff_lower = 0.4,
  force = FALSE,
  sleep_time = 8,
  ...
)
}
\arguments{
\item{file_path}{A character vector of file paths or directories to be screened. Directories will be processed recursively, with files in sub-directories being combined into a single document for screening.}

\item{prompt}{A character string containing the screening prompt. Required if \code{protocol_file_path} is not provided.}

\item{protocol_file_path}{Path to a file (.txt, .md, .pdf, .docx) containing the screening protocol.}

\item{api_key}{Your OpenAI API key. Defaults to \code{get_api_key()}.}

\item{vector_stores_name}{A name for the OpenAI vector store to be created for the screening session.}

\item{model}{Character string with the name of the completion model. Can take
multiple OpenAI models. Default = \code{"gpt-4o-mini"}.
Find available models at \url{https://platform.openai.com/docs/models}.}

\item{top_p}{An alternative to sampling with temperature, called nucleus sampling,
where the model considers the results of the tokens with top_p probability mass.
So 0.1 means only the tokens comprising the top 10\% probability mass are considered.
OpenAI recommends altering this or temperature but not both. Default is 1.}

\item{temperature}{Controls randomness: lowering results in less random completions.
As the temperature approaches zero, the model will become deterministic and repetitive. Default is 0.7.}

\item{decision_description}{Logical indicating whether to include detailed descriptions
of decisions. Default is \code{FALSE}.}

\item{assistant_name, assistant_description, assistant_instructions}{Configuration for the OpenAI assistant.}

\item{messages}{Logical indicating whether to print messages embedded in the function.
Default is \code{TRUE}.}

\item{reps}{Numerical value indicating the number of times the same
question should be sent to OpenAI's API models. This can be useful to test consistency
between answers. Default is \code{1}.}

\item{max_tries, max_seconds}{Cap the maximum number of attempts with
\code{max_tries} or the total elapsed time from the first request with
\code{max_seconds}. If neither option is supplied, it will not retry.}

\item{time_info}{Logical indicating whether the run time of each
request/question should be included in the data. Default = \code{TRUE}.}

\item{token_info}{Logical indicating whether the number of prompt and completion tokens
per request should be included in the output data. Default = \code{TRUE}.}

\item{is_transient}{A predicate function that takes a single argument
(the response) and returns \code{TRUE} or \code{FALSE} specifying whether or not
the response represents a transient error.}

\item{backoff}{A function that takes a single argument (the number of failed
attempts so far) and returns the number of seconds to wait.}

\item{after}{A function that takes a single argument (the response) and
returns either a number of seconds to wait or \code{NULL}, which indicates
that the \code{backoff} strategy should be used instead.}

\item{rpm}{Numerical value indicating the number of requests per minute (rpm)
available for the specified api key.}

\item{seed_par}{Numerical value for a seed to ensure that proper,
parallel-safe random numbers are produced.}

\item{progress}{Logical indicating whether a progress bar should be shown when running
the screening in parallel. Default is \code{TRUE}.}

\item{incl_cutoff_upper}{Numerical value indicating the probability threshold
for which a study should be included. Default is 0.5.}

\item{incl_cutoff_lower}{Numerical value indicating the probability threshold
above which studies should be checked by a human. Default is 0.4.}

\item{force}{Logical argument indicating whether to force the function to use more than
10 iterations or certain models. Default is \code{FALSE}.}

\item{sleep_time}{Time in seconds to wait between checking run status. Default is 8.}

\item{...}{Further arguments to pass to the request body.}
}
\value{
An object of class \code{gpt_ftscreen}. The object is a list containing the following
components:
\item{answer_data}{A data frame with all individual answers from the model.}
\item{answer_data_aggregated}{A data frame with the summarized, probabilistic inclusion decision for each file across multiple repeated questions (only when reps > 1).}
\item{error_data}{A data frame with failed requests (only included if errors occurred).}
\item{run_date}{The date when the screening was conducted.}
\item{n_files, n_prompts, n_models, n_combinations, n_runs}{Counts of inputs and processing runs.}
}
\description{
This function supports the conduct of full-text screening with OpenAI API models in R.
It uses the OpenAI Assistants API to process local documents (e.g., PDFs, text files).
The function allows you to run screening across multiple prompts and with
repeated questions to check for consistency across answers. It uses native function calling
to structure the model's output.
}
\note{
The \code{answer_data_aggregated} data (only present when reps > 1) contains the following variables:
\tabular{lll}{
\bold{title} \tab \code{character} \tab The filename of the screened document. \cr
\bold{model} \tab \code{character} \tab The specific model used. \cr
\bold{promptid} \tab \code{integer} \tab The prompt ID. \cr
\bold{prompt} \tab \code{character} \tab The prompt used for screening. \cr
\bold{incl_p} \tab \code{numeric} \tab The probability of inclusion across repeated responses. \cr
\bold{final_decision_gpt} \tab \code{character} \tab The final decision: 'Include', 'Exclude', or 'Check'. \cr
\bold{final_decision_gpt_num} \tab \code{integer} \tab The final numeric decision: 1 for include/check, 0 for exclude. \cr
\bold{reps} \tab \code{integer} \tab The number of repetitions for the question. \cr
\bold{n_mis_answers} \tab \code{integer} \tab The number of missing responses. \cr
\bold{supplementary} \tab \code{character} \tab Indicates if supplementary material was detected ('yes'/'no'). \cr
\bold{longest_answer} \tab \code{character} \tab The longest detailed description from responses (if \code{decision_description = TRUE}). \cr
}
\if{html}{\out{<br>}}
The \code{answer_data} data contains the following variables:
\tabular{lll}{
\bold{studyid} \tab \code{integer} \tab The study ID of the file. \cr
\bold{title} \tab \code{character} \tab The filename of the screened document. \cr
\bold{promptid} \tab \code{integer} \tab The prompt ID. \cr
\bold{prompt} \tab \code{character} \tab The prompt used for screening. \cr
\bold{model} \tab \code{character} \tab The specific model used. \tr
\bold{iterations} \tab \code{numeric} \tab The repetition number for the question. \cr
\bold{decision_gpt} \tab \code{character} \tab The raw decision from the model ('1', '0', or '1.1'). \cr
\bold{detailed_description} \tab \code{character} \tab A detailed description of the decision (if \code{decision_description = TRUE}). \cr
\bold{supplementary} \tab \code{character} \tab Indicates if supplementary material was detected ('yes'/'no'). \cr
\bold{decision_binary} \tab \code{integer} \tab The binary decision (1 for inclusion/uncertainty, 0 for exclusion). \cr
\bold{run_time} \tab \code{numeric} \tab The time taken for the request. \cr
\bold{prompt_tokens} \tab \code{integer} \tab The number of prompt tokens used. \cr
\bold{completion_tokens} \tab \code{integer} \tab The number of completion tokens used. \cr
}
}
\examples{
\dontrun{

set_api_key()

file_path <- "path/to/your/full_text_files"
protocol_file <- "path/to/your/protocol_file.txt"

# --- Run screening using the protocol file ---
result_protocol <- ftscreen(
  file_path = file_path,
  protocol_file_path = protocol_file,
  vector_stores_name = "TestFTScreenProtocol",
  model = "gpt-4o-mini",
  decision_description = TRUE,
  reps = 1,
  assistant_instructions = "
  You are a helpful agent that reviews files to determine their relevance based on specific protocols.

  CRITICAL: You must follow this EXACT two-step process:

  STEP 1: SUPPLEMENTARY CHECK ONLY
  - Use the supplementary_check function to identify if the text contains references to
    supplementary materials, appendices, or additional information.
  - This step is ONLY about identifying supplementary content - do NOT make any inclusion decisions here.

  STEP 2: PROTOCOL EVALUATION AND INCLUSION DECISION
  - Carefully review the provided protocol criteria.
  - Evaluate the study against ALL relevant criteria in the protocol.
  - Base your decision solely on whether the study meets the protocol criteria.

  IMPORTANT REMINDERS:
  - The supplementary check is separate from the inclusion decision.
  - If the study meets the protocol criteria, then it should be included in further studies.
  - Be explicit about whether the study should be included or excluded based on the protocol evaluation.
  - Provide detailed reasoning for your decision when detailed_description is enabled"
)

print(result_protocol$answer_data)


# --- Run screening using traditional prompts ---

prompts <- c("
Does this study focus on an intervention aimed at improving children's language, 
reading/literacy, or mathematical skills?
",
"Is this study written in English?",
"Does this study involve children aged 3 to 4 years old?"
)

result_prompts <- ftscreen(
  file_path = file_path,
  prompt = prompts,
  vector_stores_name = "TestFTScreenPrompts",
  model = "gpt-4o-mini",
  decision_description = TRUE,
  reps = 1
)

print(result_prompts$answer_data)
}
}
