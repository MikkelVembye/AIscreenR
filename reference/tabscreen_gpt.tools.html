<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Title and abstract screening with GPT API models using function calls via the tools argument — tabscreen_gpt.tools • AIscreenR</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Title and abstract screening with GPT API models using function calls via the tools argument — tabscreen_gpt.tools"><meta name="description" content="

This function supports the conduct of title and abstract screening with GPT API models in R.
Specifically, it allows the user to draw on GPT-3.5, GPT-4, GPT-4o, GPT-4o-mini, and fine-tuned models.
The function allows to run title and abstract screening across multiple prompts and with
repeated questions to check for consistency across answers. All of which can be done in parallel.
The function draws on the newly developed function calling which is called via the
tools argument in the request body. This is the main different between tabscreen_gpt.tools()
and tabscreen_gpt.original(). Function calls ensure more reliable and consistent responses to ones
requests. See Vembye et al. (2024)
for guidance on how adequately to conduct title and abstract screening with GPT models."><meta property="og:description" content="

This function supports the conduct of title and abstract screening with GPT API models in R.
Specifically, it allows the user to draw on GPT-3.5, GPT-4, GPT-4o, GPT-4o-mini, and fine-tuned models.
The function allows to run title and abstract screening across multiple prompts and with
repeated questions to check for consistency across answers. All of which can be done in parallel.
The function draws on the newly developed function calling which is called via the
tools argument in the request body. This is the main different between tabscreen_gpt.tools()
and tabscreen_gpt.original(). Function calls ensure more reliable and consistent responses to ones
requests. See Vembye et al. (2024)
for guidance on how adequately to conduct title and abstract screening with GPT models."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">AIscreenR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.1.1.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/Using-GPT-API-Models-For-Screening.html">Using OpenAI's GPT API models for Title and Abstract Screening in Systematic Reviews</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/MikkelVembye/AIscreenR/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Title and abstract screening with GPT API models using function calls via the tools argument</h1>
      <small class="dont-index">Source: <a href="https://github.com/MikkelVembye/AIscreenR/blob/main/R/tabscreen_gpt.R" class="external-link"><code>R/tabscreen_gpt.R</code></a></small>
      <div class="d-none name"><code>tabscreen_gpt.tools.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable" class="external-link"><img src="figures/lifecycle-stable.svg" alt="[Stable]"></a><br><br>
This function supports the conduct of title and abstract screening with GPT API models in R.
Specifically, it allows the user to draw on GPT-3.5, GPT-4, GPT-4o, GPT-4o-mini, and fine-tuned models.
The function allows to run title and abstract screening across multiple prompts and with
repeated questions to check for consistency across answers. All of which can be done in parallel.
The function draws on the newly developed function calling which is called via the
tools argument in the request body. This is the main different between <code>tabscreen_gpt.tools()</code>
and <code><a href="tabscreen_gpt.original.html">tabscreen_gpt.original()</a></code>. Function calls ensure more reliable and consistent responses to ones
requests. See <a href="https://osf.io/preprints/osf/yrhzm" class="external-link">Vembye et al. (2024)</a>
for guidance on how adequately to conduct title and abstract screening with GPT models.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">tabscreen_gpt.tools</span><span class="op">(</span><span class="va">data</span>, <span class="va">prompt</span>, <span class="va">studyid</span>, <span class="va">title</span>, <span class="va">abstract</span>,</span>
<span>   model <span class="op">=</span> <span class="st">"gpt-4o-mini"</span>, role <span class="op">=</span> <span class="st">"user"</span>, tools <span class="op">=</span> <span class="cn">NULL</span>, tool_choice <span class="op">=</span> <span class="cn">NULL</span>, top_p <span class="op">=</span> <span class="fl">1</span>,</span>
<span>   time_info <span class="op">=</span> <span class="cn">TRUE</span>, token_info <span class="op">=</span> <span class="cn">TRUE</span>, api_key <span class="op">=</span> <span class="fu"><a href="get_api_key.html">get_api_key</a></span><span class="op">(</span><span class="op">)</span>, max_tries <span class="op">=</span> <span class="fl">16</span>,</span>
<span>   max_seconds <span class="op">=</span> <span class="cn">NULL</span>, is_transient <span class="op">=</span> <span class="va">gpt_is_transient</span>, backoff <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>   after <span class="op">=</span> <span class="cn">NULL</span>, rpm <span class="op">=</span> <span class="fl">10000</span>, reps <span class="op">=</span> <span class="fl">1</span>, seed_par <span class="op">=</span> <span class="cn">NULL</span>, progress <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>   decision_description <span class="op">=</span> <span class="cn">FALSE</span>, messages <span class="op">=</span> <span class="cn">TRUE</span>, incl_cutoff_upper <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>   incl_cutoff_lower <span class="op">=</span> <span class="cn">NULL</span>, force <span class="op">=</span> <span class="cn">FALSE</span>, fine_tuned <span class="op">=</span> <span class="cn">FALSE</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">tabscreen_gpt</span><span class="op">(</span><span class="va">data</span>, <span class="va">prompt</span>, <span class="va">studyid</span>, <span class="va">title</span>, <span class="va">abstract</span>,</span>
<span>   model <span class="op">=</span> <span class="st">"gpt-4o-mini"</span>, role <span class="op">=</span> <span class="st">"user"</span>, tools <span class="op">=</span> <span class="cn">NULL</span>, tool_choice <span class="op">=</span> <span class="cn">NULL</span>, top_p <span class="op">=</span> <span class="fl">1</span>,</span>
<span>   time_info <span class="op">=</span> <span class="cn">TRUE</span>, token_info <span class="op">=</span> <span class="cn">TRUE</span>, api_key <span class="op">=</span> <span class="fu"><a href="get_api_key.html">get_api_key</a></span><span class="op">(</span><span class="op">)</span>, max_tries <span class="op">=</span> <span class="fl">16</span>,</span>
<span>   max_seconds <span class="op">=</span> <span class="cn">NULL</span>, is_transient <span class="op">=</span> <span class="va">gpt_is_transient</span>, backoff <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>   after <span class="op">=</span> <span class="cn">NULL</span>, rpm <span class="op">=</span> <span class="fl">10000</span>, reps <span class="op">=</span> <span class="fl">1</span>, seed_par <span class="op">=</span> <span class="cn">NULL</span>, progress <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>   decision_description <span class="op">=</span> <span class="cn">FALSE</span>, messages <span class="op">=</span> <span class="cn">TRUE</span>, incl_cutoff_upper <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>   incl_cutoff_lower <span class="op">=</span> <span class="cn">NULL</span>, force <span class="op">=</span> <span class="cn">FALSE</span>, fine_tuned <span class="op">=</span> <span class="cn">FALSE</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-data">data<a class="anchor" aria-label="anchor" href="#arg-data"></a></dt>
<dd><p>Dataset containing the titles and abstracts.</p></dd>


<dt id="arg-prompt">prompt<a class="anchor" aria-label="anchor" href="#arg-prompt"></a></dt>
<dd><p>Prompt(s) to be added before the title and abstract.</p></dd>


<dt id="arg-studyid">studyid<a class="anchor" aria-label="anchor" href="#arg-studyid"></a></dt>
<dd><p>Unique Study ID. If missing, this is generated
automatically.</p></dd>


<dt id="arg-title">title<a class="anchor" aria-label="anchor" href="#arg-title"></a></dt>
<dd><p>Name of the variable containing the title information.</p></dd>


<dt id="arg-abstract">abstract<a class="anchor" aria-label="anchor" href="#arg-abstract"></a></dt>
<dd><p>Name of variable containing the abstract information.</p></dd>


<dt id="arg-model">model<a class="anchor" aria-label="anchor" href="#arg-model"></a></dt>
<dd><p>Character string with the name of the completion model. Can take
multiple models. Default is the latest <code>"gpt-4o-mini"</code>.
Find available model at
<a href="https://platform.openai.com/docs/models/model-endpoint-compatibility" class="external-link">https://platform.openai.com/docs/models/model-endpoint-compatibility</a>.</p></dd>


<dt id="arg-role">role<a class="anchor" aria-label="anchor" href="#arg-role"></a></dt>
<dd><p>Character string indicating the role of the user. Default is <code>"user"</code>.</p></dd>


<dt id="arg-tools">tools<a class="anchor" aria-label="anchor" href="#arg-tools"></a></dt>
<dd><p>This argument allows this user to apply customized functions.
See <a href="https://platform.openai.com/docs/api-reference/chat/create#chat-create-tools" class="external-link">https://platform.openai.com/docs/api-reference/chat/create#chat-create-tools</a>.
Default is <code>NULL</code>. If not specified the default function calls from <code>AIscreenR</code> are used.</p></dd>


<dt id="arg-tool-choice">tool_choice<a class="anchor" aria-label="anchor" href="#arg-tool-choice"></a></dt>
<dd><p>If a customized function is provided this argument
'controls which (if any) tool is called by the model' (OpenAI). Default is <code>NULL</code>.
If set to <code>NULL</code> when using a customized function, the default is <code>"auto"</code>.
See <a href="https://platform.openai.com/docs/api-reference/chat/create#chat-create-tool_choice" class="external-link">https://platform.openai.com/docs/api-reference/chat/create#chat-create-tool_choice</a>.</p></dd>


<dt id="arg-top-p">top_p<a class="anchor" aria-label="anchor" href="#arg-top-p"></a></dt>
<dd><p>'An alternative to sampling with temperature, called nucleus sampling,
where the model considers the results of the tokens with top_p probability mass.
So 0.1 means only the tokens comprising the top 10% probability mass are considered.
We generally recommend altering this or temperature but not both.' (OpenAI). Default is 1.
Find documentation at
<a href="https://platform.openai.com/docs/api-reference/chat/create#chat/create-top_p" class="external-link">https://platform.openai.com/docs/api-reference/chat/create#chat/create-top_p</a>.</p></dd>


<dt id="arg-time-info">time_info<a class="anchor" aria-label="anchor" href="#arg-time-info"></a></dt>
<dd><p>Logical indicating whether the run time of each
request/question should be included in the data. Default is <code>TRUE</code>.</p></dd>


<dt id="arg-token-info">token_info<a class="anchor" aria-label="anchor" href="#arg-token-info"></a></dt>
<dd><p>Logical indicating whether token information should be included
in the output data. Default is <code>TRUE</code>. When <code>TRUE</code>, the output object will
include price information of the conducted screening.</p></dd>


<dt id="arg-api-key">api_key<a class="anchor" aria-label="anchor" href="#arg-api-key"></a></dt>
<dd><p>Numerical value with your personal API key. Default setting draws
on the <code><a href="get_api_key.html">get_api_key()</a></code> to retrieve the API key from the R environment, so that the key is not
compromised. The API key can be added to the R environment via <code><a href="set_api_key.html">set_api_key()</a></code>
or by using <code><a href="https://usethis.r-lib.org/reference/edit.html" class="external-link">usethis::edit_r_environ()</a></code>. In the <code>.Renviron</code> file, write <code>CHATGPT_KEY=INSERT_YOUR_KEY_HERE</code>.
After entering the API key, close and save the <code>.Renviron</code> file and restart <code>RStudio</code> (ctrl + shift + F10).
Alternatively, one can use <code><a href="https://httr2.r-lib.org/reference/secrets.html" class="external-link">httr2::secret_make_key()</a></code>, <code><a href="https://httr2.r-lib.org/reference/secrets.html" class="external-link">httr2::secret_encrypt()</a></code>, and
<code><a href="https://httr2.r-lib.org/reference/secrets.html" class="external-link">httr2::secret_decrypt()</a></code> to scramble and decrypt the API key.</p></dd>


<dt id="arg-max-tries-max-seconds">max_tries, max_seconds<a class="anchor" aria-label="anchor" href="#arg-max-tries-max-seconds"></a></dt>
<dd><p>'Cap the maximum number of attempts with
<code>max_tries</code> or the total elapsed time from the first request with
<code>max_seconds</code>. If neither option is supplied (the default), <code><a href="https://httr2.r-lib.org/reference/req_perform.html" class="external-link">httr2::req_perform()</a></code>
will not retry' (Wickham, 2023). The default of <code>max_tries</code> is 16.</p></dd>


<dt id="arg-is-transient">is_transient<a class="anchor" aria-label="anchor" href="#arg-is-transient"></a></dt>
<dd><p>'A predicate function that takes a single argument
(the response) and returns <code>TRUE</code> or <code>FALSE</code> specifying whether or not
the response represents a transient error' (Wickham, 2023). This function runs
automatically in the AIscreenR but can be customized by the user if necessary.</p></dd>


<dt id="arg-backoff">backoff<a class="anchor" aria-label="anchor" href="#arg-backoff"></a></dt>
<dd><p>'A function that takes a single argument (the number of failed
attempts so far) and returns the number of seconds to wait' (Wickham, 2023).</p></dd>


<dt id="arg-after">after<a class="anchor" aria-label="anchor" href="#arg-after"></a></dt>
<dd><p>'A function that takes a single argument (the response) and
returns either a number of seconds to wait or <code>NULL</code>, which indicates
that a precise wait time is not available that the <code>backoff</code> strategy
should be used instead' (Wickham, 2023).</p></dd>


<dt id="arg-rpm">rpm<a class="anchor" aria-label="anchor" href="#arg-rpm"></a></dt>
<dd><p>Numerical value indicating the number of requests per minute (rpm)
available for the specified model. Find more information at
<a href="https://platform.openai.com/docs/guides/rate-limits/what-are-the-rate-limits-for-our-api" class="external-link">https://platform.openai.com/docs/guides/rate-limits/what-are-the-rate-limits-for-our-api</a>.
Alternatively, use <code><a href="rate_limits_per_minute.html">rate_limits_per_minute()</a></code>.</p></dd>


<dt id="arg-reps">reps<a class="anchor" aria-label="anchor" href="#arg-reps"></a></dt>
<dd><p>Numerical value indicating the number of times the same
question should be send to the server. This can be useful to test consistency
between answers, and/or can be used to make inclusion judgments based on how many times
a study has been included across a the given number of screenings.
Default is <code>1</code> but when using gpt-3.5-turbo models or gpt-4o-mini,
we recommend setting this value to <code>10</code> to catch model uncertainty.</p></dd>


<dt id="arg-seed-par">seed_par<a class="anchor" aria-label="anchor" href="#arg-seed-par"></a></dt>
<dd><p>Numerical value for a seed to ensure that proper,
parallel-safe random numbers are produced.</p></dd>


<dt id="arg-progress">progress<a class="anchor" aria-label="anchor" href="#arg-progress"></a></dt>
<dd><p>Logical indicating whether a progress line should be shown when running
the title and abstract screening in parallel. Default is <code>TRUE</code>.</p></dd>


<dt id="arg-decision-description">decision_description<a class="anchor" aria-label="anchor" href="#arg-decision-description"></a></dt>
<dd><p>Logical indicating whether a detailed description should follow
the decision made by GPT. Default is <code>FALSE</code>. When conducting large-scale screening,
we generally recommend not using this feature as it will substantially increase the cost of the
screening. We generally recommend using it when encountering disagreements between GPT and
human decisions.</p></dd>


<dt id="arg-messages">messages<a class="anchor" aria-label="anchor" href="#arg-messages"></a></dt>
<dd><p>Logical indicating whether to print messages embedded in the function.
Default is <code>TRUE</code>.</p></dd>


<dt id="arg-incl-cutoff-upper">incl_cutoff_upper<a class="anchor" aria-label="anchor" href="#arg-incl-cutoff-upper"></a></dt>
<dd><p>Numerical value indicating the probability threshold
for which a studies should be included. ONLY relevant when the same questions is requested
multiple times (i.e., when any reps &gt; 1). Default is 0.5, indicating that
titles and abstracts should only be included if GPT has included the study more than 50 percent of the times.</p></dd>


<dt id="arg-incl-cutoff-lower">incl_cutoff_lower<a class="anchor" aria-label="anchor" href="#arg-incl-cutoff-lower"></a></dt>
<dd><p>Numerical value indicating the probability threshold
above which studies should be check by a human. ONLY relevant when the same questions is requested
multiple times (i.e., when any reps &gt; 1). Default is 0.4, meaning
that if you ask GPT the same questions 10 times and it includes the
title and abstract 4 times, we suggest that the study should be check by a human.</p></dd>


<dt id="arg-force">force<a class="anchor" aria-label="anchor" href="#arg-force"></a></dt>
<dd><p>Logical argument indicating whether to force the function to use more than
10 iterations for gpt-3.5 models and more than 1 iteration for gpt-4 models other than gpt-4o-mini.
This argument is developed to avoid the conduct of wrong and extreme sized screening.
Default is <code>FALSE</code>.</p></dd>


<dt id="arg-fine-tuned">fine_tuned<a class="anchor" aria-label="anchor" href="#arg-fine-tuned"></a></dt>
<dd><p>Logical indicating whether a fine-tuned model is used. Default is <code>FALSE</code>.</p></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>Further argument to pass to the request body.
See <a href="https://platform.openai.com/docs/api-reference/chat/create" class="external-link">https://platform.openai.com/docs/api-reference/chat/create</a>.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>An object of class <code>'gpt'</code>. The object is a list containing the following
datasets and components:</p>
<dl><dt>answer_data</dt>
<dd><p>dataset of class <code>'gpt_tbl'</code> with all individual answers.</p></dd>

<dt>price_dollar</dt>
<dd><p>numerical value indicating the total price (in USD) of the screening.</p></dd>

<dt>price_data</dt>
<dd><p>dataset with prices across all gpt models used for screening.</p></dd>

<dt>run_date</dt>
<dd><p>string indicating the date when the screening was ran. In some frameworks,
time details are considered important to report (see e.g., Thomas et al., 2024).</p></dd>

<dt>...</dt>
<dd><p>some additional attributed values/components, including an attributed list with the arguments used in the function.
These are used in  <code><a href="screen_errors.html">screen_errors()</a></code> to re-screen transient errors.</p></dd>


</dl><p>If the same question is requested multiple times, the object will also contain the
following dataset with results aggregated across the iterated requests/questions.</p>
<dl><dt>answer_data_aggregated</dt>
<dd><p>dataset of class <code>'gpt_agg_tbl'</code> with the summarized, probabilistic inclusion decision
for each title and abstract across multiple repeated questions.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="note">Note<a class="anchor" aria-label="anchor" href="#note"></a></h2>
    <p>The <code>answer_data</code> data contains the following <em>mandatory</em> variables:</p><table class="table table"><tr><td><b>studyid</b></td><td><code>integer</code></td><td>indicating the study ID of the reference.</td></tr><tr><td><b>title</b></td><td><code>character</code></td><td>indicating the title of the reference.</td></tr><tr><td><b>abstract</b></td><td><code>character</code></td><td>indicating the abstract of the reference.</td></tr><tr><td><b>promptid</b></td><td><code>integer</code></td><td>indicating the prompt ID.</td></tr><tr><td><b>prompt</b></td><td><code>character</code></td><td>indicating the prompt.</td></tr><tr><td><b>model</b></td><td><code>character</code></td><td>indicating the specific gpt-model used.</td></tr><tr><td><b>iterations</b></td><td><code>numeric</code></td><td>indicating the number of times the same question has been sent to OpenAI's GPT API models.</td></tr><tr><td><b>question</b></td><td><code>character</code></td><td>indicating the final question sent to OpenAI's GPT API models.</td></tr><tr><td><b>top_p</b></td><td><code>numeric</code></td><td>indicating the applied top_p.</td></tr><tr><td><b>decision_gpt</b></td><td><code>character</code></td><td>indicating the raw gpt decision - either <code>"1", "0", "1.1"</code> for inclusion, exclusion, or uncertainty, respectively.</td></tr><tr><td><b>detailed_description</b></td><td><code>character</code></td><td>indicating detailed description of the given decision made by OpenAI's GPT API models.
ONLY included if the detailed function calling function is used. See 'Examples' below for how to use this function.</td></tr><tr><td><b>decision_binary</b></td><td><code>integer</code></td><td>indicating the binary gpt decision,
that is 1 for inclusion and 0 for exclusion. 1.1 decision are coded equal to 1 in this case.</td></tr><tr><td><b>prompt_tokens</b></td><td><code>integer</code></td><td>indicating the number of prompt tokens sent to the server for the given request.</td></tr><tr><td><b>completion_tokens</b></td><td><code>integer</code></td><td>indicating the number of completion tokens sent to the server for the given request.</td></tr><tr><td><b>submodel</b></td><td><code>character</code></td><td>indicating the exact (sub)model used for screening.</td></tr><tr><td><b>run_time</b></td><td><code>numeric</code></td><td>indicating the time it took to obtain a response from the server for the given request.</td></tr><tr><td><b>run_date</b></td><td><code>character</code></td><td>indicating the date the given response was received.</td></tr><tr><td><b>n</b></td><td><code>integer</code></td><td>indicating iteration ID. Is only different from 1, when <code>reps &gt; 1</code>.</td></tr></table><p><br>
If any requests failed, the <code>gpt</code> object contains an
error dataset (<code>error_data</code>) containing the same variables as <code>answer_data</code>
but with failed request references only.
<br></p>

<p>When the same question is requested multiple times, the <code>answer_data_aggregated</code> data contains the following <em>mandatory</em> variables:</p><table class="table table"><tr><td><b>studyid</b></td><td><code>integer</code></td><td>indicating the study ID of the reference.</td></tr><tr><td><b>title</b></td><td><code>character</code></td><td>indicating the title of the reference.</td></tr><tr><td><b>abstract</b></td><td><code>character</code></td><td>indicating the abstract of the reference.</td></tr><tr><td><b>promptid</b></td><td><code>integer</code></td><td>indicating the prompt ID.</td></tr><tr><td><b>prompt</b></td><td><code>character</code></td><td>indicating the prompt.</td></tr><tr><td><b>model</b></td><td><code>character</code></td><td>indicating the specific gpt-model used.</td></tr><tr><td><b>question</b></td><td><code>character</code></td><td>indicating the final question sent to OpenAI's GPT API models.</td></tr><tr><td><b>top_p</b></td><td><code>numeric</code></td><td>indicating the applied top_p.</td></tr><tr><td><b>incl_p</b></td><td><code>numeric</code></td><td>indicating the probability of inclusion calculated across multiple repeated responses on the same title and abstract.</td></tr><tr><td><b>final_decision_gpt</b></td><td><code>character</code></td><td>indicating the final decision reached by gpt - either 'Include', 'Exclude', or 'Check'.</td></tr><tr><td><b>final_decision_gpt_num</b></td><td><code>integer</code></td><td>indicating the final numeric decision reached by gpt - either 1 or 0.</td></tr><tr><td><b>longest_answer</b></td><td><code>character</code></td><td>indicating the longest gpt response obtained
across multiple repeated responses on the same title and abstract. Only included when <code>decision_description = TRUE</code>.
See 'Examples' below for how to use this function.</td></tr><tr><td><b>reps</b></td><td><code>integer</code></td><td>indicating the number of times the same question has been sent to OpenAI's GPT API models.</td></tr><tr><td><b>n_mis_answers</b></td><td><code>integer</code></td><td>indicating the number of missing responses.</td></tr><tr><td><b>submodel</b></td><td><code>character</code></td><td>indicating the exact (sub)model used for screening.</td></tr></table><p><br></p>
<p>The <code>price_data</code> data contains the following variables:</p><table class="table table"><tr><td><b>prompt</b></td><td><code>character</code></td><td>if multiple prompts are used this variable indicates the given prompt-id.</td></tr><tr><td><b>model</b></td><td><code>character</code></td><td>the specific gpt model used.</td></tr><tr><td><b>iterations</b></td><td><code>integer</code></td><td>indicating the number of times the same question was requested.</td></tr><tr><td><b>input_price_dollar</b></td><td><code>integer</code></td><td>price for all prompt/input tokens for the correspondent gpt-model.</td></tr><tr><td><b>output_price_dollar</b></td><td><code>integer</code></td><td>price for all completion/output tokens for the correspondent gpt-model.</td></tr><tr><td><b>total_price_dollar</b></td><td><code>integer</code></td><td>total price for all tokens for the correspondent gpt-model.</td></tr></table><p>Find current token pricing at <a href="https://openai.com/pricing" class="external-link">https://openai.com/pricing</a> or <a href="model_prizes.html">model_prizes</a>.</p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Vembye, M. H., Christensen, J., Mølgaard, A. B., &amp; Schytt, F. L. W. (2024)
<em>GPT API Models Can Function as Highly Reliable Second Screeners of Titles and Abstracts in Systematic Reviews:
A Proof of Concept and Common Guidelines</em> <a href="https://osf.io/preprints/osf/yrhzm" class="external-link">https://osf.io/preprints/osf/yrhzm</a></p>
<p>Thomas, J. et al. (2024).
Responsible AI in Evidence SynthEsis (RAISE): guidance and recommendations.
<a href="https://osf.io/cn7x4" class="external-link">https://osf.io/cn7x4</a></p>
<p>Wickham H (2023).
<em>httr2: Perform HTTP Requests and Process the Responses</em>.
<a href="https://httr2.r-lib.org" class="external-link">https://httr2.r-lib.org</a>, <a href="https://github.com/r-lib/httr2" class="external-link">https://github.com/r-lib/httr2</a>.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># \dontrun{</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://future.futureverse.org" class="external-link">future</a></span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="fu"><a href="set_api_key.html">set_api_key</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">prompt</span> <span class="op">&lt;-</span> <span class="st">"Is this study about a Functional Family Therapy (FFT) intervention?"</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="va">multisession</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="fu">tabscreen_gpt</span><span class="op">(</span></span></span>
<span class="r-in"><span>  data <span class="op">=</span> <span class="va">filges2015_dat</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>,<span class="op">]</span>,</span></span>
<span class="r-in"><span>  prompt <span class="op">=</span> <span class="va">prompt</span>,</span></span>
<span class="r-in"><span>  studyid <span class="op">=</span> <span class="va">studyid</span>,</span></span>
<span class="r-in"><span>  title <span class="op">=</span> <span class="va">title</span>,</span></span>
<span class="r-in"><span>  abstract <span class="op">=</span> <span class="va">abstract</span></span></span>
<span class="r-in"><span>  <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="va">sequential</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span> <span class="co"># Get detailed descriptions of the gpt decisions.</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span> <span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="va">multisession</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span> <span class="fu">tabscreen_gpt</span><span class="op">(</span></span></span>
<span class="r-in"><span>   data <span class="op">=</span> <span class="va">filges2015_dat</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>,<span class="op">]</span>,</span></span>
<span class="r-in"><span>   prompt <span class="op">=</span> <span class="va">prompt</span>,</span></span>
<span class="r-in"><span>   studyid <span class="op">=</span> <span class="va">studyid</span>,</span></span>
<span class="r-in"><span>   title <span class="op">=</span> <span class="va">title</span>,</span></span>
<span class="r-in"><span>   abstract <span class="op">=</span> <span class="va">abstract</span>,</span></span>
<span class="r-in"><span>   decision_description <span class="op">=</span> <span class="cn">TRUE</span></span></span>
<span class="r-in"><span> <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="va">sequential</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="co"># }</span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Mikkel H. Vembye, Thomas Olsen.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

