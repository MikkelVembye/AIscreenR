devtools::load_all()
file_path <- c("C:/Users/B375477/Desktop/Thomas_aiscreenr/full_text/texts/test1.txt"
)
prompts <- trimws(c(
"Does this study focus on an intervention aimed at improving children's language, reading/literacy, or mathematical skills?",
"Is this study written in English?",
"Does this study involve children aged 3 to 4 years old?"
))
result_prompts <- ftscreen(
file_path = file_path,
prompt = prompts,
vector_stores_name = "TestFTScreenPrompts",
model = "gpt-4o-mini",
decision_description = TRUE,
temperature = 0,
reps = 1
)
print(result_prompts$answer_data)
print(result_prompts$answer_data$detailed_description)
print(result_prompts$answer_data$decision_binary)
print(result_prompts$answer_data$supplementary)
chat <- function(data, prompt, model = "gpt-5-nano", verbosity = NULL, reasoning_effort = NULL) {
base_url <- "https://api.openai.com/v1"
api_key <- Sys.getenv("CHATGPT_KEY")
# Initialize an empty data frame to store the results
results <- tibble::tibble(
Title = character(),
StudyID = character(),
decision_gpt = character(),
PromptTokens = integer(),
CompletionTokens = integer(),
TotalTokens = integer()
)
# Loop over each row of the data
for (i in 1:nrow(data)) {
# Extract the study details
study_details <- paste(data[i, "title"], data[i, "abstract"], sep = " ")
# Create the user message
user_message <- list(
list(role = "user", content = paste0(prompt, " ", study_details))
)
# Create the request body
body <- list(model = model,
messages = user_message,
verbosity = verbosity,
reasoning_effort = reasoning_effort)
# Make the request
req <- httr2::request(base_url)
resp <-
req |>
httr2::req_url_path_append("chat/completions") |>
httr2::req_auth_bearer_token(token = api_key) |>
httr2::req_headers("Content-Type" = "application/json") |>
httr2::req_user_agent("Thomas Olsen") |>
httr2::req_body_json(body) |>
httr2::req_retry(max_tries = 4) |>
httr2::req_throttle(rate = 15) |>
httr2::req_perform() |>
httr2::resp_body_json()
# Extract the decision_gpt from the response
decision_gpt <- resp$choices[[1]]$message$content
# New: extract token usage and print
usage <- resp$usage
prompt_tokens <- if (!is.null(usage$prompt_tokens)) usage$prompt_tokens else NA_integer_
completion_tokens <- if (!is.null(usage$completion_tokens)) usage$completion_tokens else NA_integer_
total_tokens <- if (!is.null(usage$total_tokens)) usage$total_tokens else NA_integer_
message(sprintf("Token usage (prompt/completion/total): %s / %s / %s",
prompt_tokens, completion_tokens, total_tokens))
# Add a new row to the results tibble
results <- tibble::add_row(
results,
Title = as.character(data[i, "title"]),
StudyID = as.character(data[i, "studyid"]),
decision_gpt = decision_gpt,
PromptTokens = prompt_tokens,
CompletionTokens = completion_tokens,
TotalTokens = total_tokens
)
}
message(sprintf("Aggregate total tokens: %s", sum(results$TotalTokens, na.rm = TRUE)))
return(results)
}
# Example usage (runs only in an interactive session)
library(tibble)
demo_data <- tibble(
studyid = c("1", "2"),
title = c("Effect of exercise on blood pressure",
"Dietary salt and hypertension"),
abstract = c(
"Randomized controlled trial assessing aerobic exercise impact on systolic blood pressure in adults.",
"Prospective cohort examining relationship between dietary sodium intake and development of hypertension."
)
)
demo_prompt <- "Is this study primarily an interventional trial?"
obj <- chat(
demo_data,
demo_prompt,
model = "gpt-4o-mini",
verbosity = "high",
reasoning_effort = "high"
)
chat <- function(data, prompt, model = "gpt-5-nano", verbosity = NULL, reasoning_effort = NULL) {
base_url <- "https://api.openai.com/v1"
api_key <- Sys.getenv("CHATGPT_KEY")
# Initialize an empty data frame to store the results
results <- tibble::tibble(
Title = character(),
StudyID = character(),
decision_gpt = character(),
PromptTokens = integer(),
CompletionTokens = integer(),
TotalTokens = integer()
)
# Loop over each row of the data
for (i in 1:nrow(data)) {
# Extract the study details
study_details <- paste(data[i, "title"], data[i, "abstract"], sep = " ")
# Create the user message
user_message <- list(
list(role = "user", content = paste0(prompt, " ", study_details))
)
# Create the request body
body <- list(model = model,
messages = user_message,
verbosity = verbosity,
reasoning_effort = reasoning_effort)
# Make the request
req <- httr2::request(base_url)
resp <-
req |>
#httr2::req_url_path_append("chat/completions") |>
httr2::req_url_path_append("responses") |>
httr2::req_auth_bearer_token(token = api_key) |>
httr2::req_headers("Content-Type" = "application/json") |>
httr2::req_user_agent("Thomas Olsen") |>
httr2::req_body_json(body) |>
httr2::req_retry(max_tries = 4) |>
httr2::req_throttle(rate = 15) |>
httr2::req_perform() |>
httr2::resp_body_json()
# Extract the decision_gpt from the response
decision_gpt <- resp$choices[[1]]$message$content
# New: extract token usage and print
usage <- resp$usage
prompt_tokens <- if (!is.null(usage$prompt_tokens)) usage$prompt_tokens else NA_integer_
completion_tokens <- if (!is.null(usage$completion_tokens)) usage$completion_tokens else NA_integer_
total_tokens <- if (!is.null(usage$total_tokens)) usage$total_tokens else NA_integer_
message(sprintf("Token usage (prompt/completion/total): %s / %s / %s",
prompt_tokens, completion_tokens, total_tokens))
# Add a new row to the results tibble
results <- tibble::add_row(
results,
Title = as.character(data[i, "title"]),
StudyID = as.character(data[i, "studyid"]),
decision_gpt = decision_gpt,
PromptTokens = prompt_tokens,
CompletionTokens = completion_tokens,
TotalTokens = total_tokens,
Usage = usage
)
}
message(sprintf("Aggregate total tokens: %s", sum(results$TotalTokens, na.rm = TRUE)))
return(results)
}
# Example usage (runs only in an interactive session)
library(tibble)
demo_data <- tibble(
studyid = c("1", "2"),
title = c("Effect of exercise on blood pressure",
"Dietary salt and hypertension"),
abstract = c(
"Randomized controlled trial assessing aerobic exercise impact on systolic blood pressure in adults.",
"Prospective cohort examining relationship between dietary sodium intake and development of hypertension."
)
)
demo_prompt <- "Is this study primarily an interventional trial?"
obj <- chat(
demo_data,
demo_prompt,
model = "gpt-4o-mini",
verbosity = "high",
reasoning_effort = "high"
)
devtools::build_site()
